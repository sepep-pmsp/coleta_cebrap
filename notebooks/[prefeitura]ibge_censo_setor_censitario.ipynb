{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "import tempfile\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "import concurrent.futures\n",
        "from glob import glob\n",
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "qoQKxKa8bELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funçoes"
      ],
      "metadata": {
        "id": "pWna0sBzbiAd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-lsQrF8axI5"
      },
      "outputs": [],
      "source": [
        "def download_files_from_ftp(url: str) -> None:\n",
        "    \"\"\"\n",
        "    Baixa um arquivo do FTP e retorna seu conteúdo em memória.\n",
        "\n",
        "    Parâmetros:\n",
        "    url (str): URL do arquivo a ser baixado.\n",
        "\n",
        "    Retorna:\n",
        "    Arquivo será baixado e extraido na pasta \"data/input\"\n",
        "    \"\"\"\n",
        "    base_path = Path(\"data\")\n",
        "    path_input = base_path / \"input\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    save_path = path_input / url.split('/')[-1]\n",
        "\n",
        "    path_input.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with open(save_path, \"wb\") as fd:\n",
        "        for chunk in response.iter_content(chunk_size=128):\n",
        "            fd.write(chunk)\n",
        "\n",
        "    with zipfile.ZipFile(save_path) as z:\n",
        "        z.extractall(path_input)\n",
        "\n",
        "def get_sp_distrito_from_csv(path_csv: str) -> pd.DataFrame:\n",
        "\n",
        "  name_file = path_csv.split('/')[-1]\n",
        "\n",
        "  temp_df = pd.read_csv(path_csv, encoding='iso-8859-1', sep=\";\", dtype=str)\n",
        "\n",
        "  df_sp_distritos = temp_df[temp_df.CD_DIST.str.contains(\"3550308\")]\n",
        "\n",
        "  return df_sp_distritos\n",
        "\n",
        "def excel_sheet_to_df( path_dicionario: str, sheet_name: str) -> pd.DataFrame:\n",
        "\n",
        "  temp_df_sheet = pd.read_excel(path_dicionario, sheet_name=sheet_name)\n",
        "\n",
        "  temp_df_sheet = temp_df_sheet[['Variável', 'Descrição']]\n",
        "\n",
        "  return temp_df_sheet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download"
      ],
      "metadata": {
        "id": "fAw8XXUWbhZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_agregados_por_distrito_csv = 'http://ftp.ibge.gov.br/Censos/Censo_Demografico_2022/Agregados_por_Setores_Censitarios/Agregados_por_Distrito_csv/'\n",
        "url_sp_distrito_geo = 'http://ftp.ibge.gov.br/Censos/Censo_Demografico_2022/Agregados_por_Setores_Censitarios/malha_com_atributos/distritos/shp/UF/SP/SP_distritos_CD2022.zip'\n",
        "url_dicionario_de_dados = 'http://ftp.ibge.gov.br/Censos/Censo_Demografico_2022/Agregados_por_Setores_Censitarios/dicionario_de_dados_agregados_por_setores_censitarios.xlsx'\n",
        "\n",
        "response = requests.get(url_agregados_por_distrito_csv)\n",
        "\n",
        "soup = BeautifulSoup(response.text)\n",
        "\n",
        "links_agregados_por_distrito_csv = [url_agregados_por_distrito_csv + a.get('href') for a in soup.select('td a') if a.get('href').count('zip')] # Coleta o link dos Arquivos\n",
        "\n",
        "links_agregados_por_distrito_csv.extend([url_sp_distrito_geo, url_dicionario_de_dados]) # Adicionando tabela Distrito Geografico e Dicionario a lista de download\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "  executor.map(download_files_from_ftp, links_agregados_por_distrito_csv)\n",
        "\n"
      ],
      "metadata": {
        "id": "JTiSv7hFcsmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separar distritos de SP"
      ],
      "metadata": {
        "id": "IVnoucUo1OFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tabela com as GeoGrafias\n",
        "geo_df_sp = gpd.read_file('/content/data/input/SP_distritos_CD2022.shp', columns=['CD_DIST', 'NM_DIST', 'geometry'])\n",
        "geo_df_sp = geo_df_sp[geo_df_sp.CD_DIST.str.contains(\"3550308\")]\n",
        "\n",
        "# Carrega o Dicionario e Prepara ele para o Rename\n",
        "path_dicionario = '/content/data/input/dicionario_de_dados_agregados_por_setores_censitarios.xlsx'\n",
        "sheet_names = ['Dicionário Básico', 'Dicionário não PCT', 'Dicionário PCT - Indígenas', 'Dicionário PCT - Quilombolas']\n",
        "\n",
        "df_dicionario = pd.concat([excel_sheet_to_df(path_dicionario, sheet_name) for sheet_name in sheet_names])\n",
        "\n",
        "dicionario_to_rename = dict(zip(df_dicionario.Variável, df_dicionario.Descrição))\n",
        "\n",
        "# Carrega e trata tabela final\n",
        "\n",
        "regex_glob = '/content/data/input/*.csv'\n",
        "\n",
        "csv_files = glob(regex_glob)\n",
        "\n",
        "temp_dfs = [get_sp_distrito_from_csv(csv_path) for csv_path in csv_files]\n",
        "\n",
        "temp_dfs.append(geo_df_sp) # Adicionando tabela Distrito Geografico\n",
        "\n",
        "first_temp_df = temp_dfs.pop(0) # Seleciona primeira tabela e remove ela da lista\n",
        "\n",
        "for temp_df in temp_dfs:\n",
        "\n",
        "  temp_df.drop('NM_DIST', axis=1, inplace=True)\n",
        "\n",
        "  first_temp_df = pd.merge(\n",
        "      first_temp_df,\n",
        "      temp_df,\n",
        "      how=\"left\",\n",
        "      on=\"CD_DIST\"\n",
        "  )\n",
        "\n",
        "first_temp_df.columns = first_temp_df.columns.str.upper() # Coloca todas as colunas como Upper para manipulação de nomes\n",
        "\n",
        "# Tratar ordem e nome das colunas\n",
        "columns_to_sorted = first_temp_df.columns[first_temp_df.columns.str.startswith('V')].sort_values().tolist()\n",
        "first_columns = first_temp_df.columns[~first_temp_df.columns.str.startswith('V')].tolist()\n",
        "column_order = first_columns + columns_to_sorted\n",
        "\n",
        "first_temp_df = first_temp_df[column_order]\n",
        "\n",
        "first_temp_df = first_temp_df.rename(columns=dicionario_to_rename)\n",
        "\n",
        "first_temp_df = first_temp_df.loc[:,~first_temp_df.columns.duplicated()] # Remove Colunas duplicadas.\n",
        "\n",
        "first_temp_df.GEOMETRY = first_temp_df.GEOMETRY.astype(str) # Transforma Geometry em string para salvar em Parquet\n",
        "\n",
        "first_temp_df.to_excel('ibge_censo_setor_censitario.xlsx', index=False) # Salvar para excel\n",
        "first_temp_df.to_parquet('ibge_censo_setor_censitario.parquet', index=False) # Salvar para Parquet"
      ],
      "metadata": {
        "id": "voaqLrPiiemk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}